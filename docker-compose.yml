services:
    # Flask is the Python web application that will run the AI chatbot.
    flask:
        build: .
        container_name: ai_flask
#        ports:
#            - "9001:9001"  # DO NOT expose the port to the host. Everything is done through the nginx container (port 8000).
        volumes:
            - .:/flaskapp
        depends_on:
            - redis
        networks:
            - far_ai
        healthcheck:
          test: [ "CMD", "curl", "-f", "http://localhost:9001/api/v1/health" ]
          interval: 30s
          timeout: 10s
          retries: 3
    # Redis is the in-memory data store that will be used to store chat histories.
    redis:
      image: redis
      container_name: ai_redis
      ports:
        - "6379:6379"
      networks:
        - far_ai
      healthcheck:
        test: [ "CMD", "redis-cli", "ping" ]
        interval: 30s
        timeout: 10s
        retries: 3
    # Nginx is the reverse proxy that sits in front of the Gunicorn server.
    # (Gunicorn is included in the requirements.txt file and started in the Dockerfile)
    nginx:
      image: nginx
      container_name: ai_nginx
      ports:
        - "8000:80"
      volumes:
        - ./nginx.conf:/etc/nginx/nginx.conf
      depends_on:
        - flask
      networks:
        - far_ai
      healthcheck:
        test: [ "CMD", "curl", "-f", "http://localhost:8000" ]
        interval: 30s
        timeout: 10s
        retries: 3

networks:
  far_ai: